# Real-time-accumulation-of-task-offloading-records-from-a-dynamic-MEC-infrastructure

The dataset contains 10,000 samples for 2,000 tasks, ensuring high-density recording with diverse interactions across devices and servers. Large-scale datasets reduce the risk of overfitting experimental models to specific cases and allow for statistically meaningful evaluations (with sufficient task variety and quantity, experimental conclusions drawn from the dataset maintain credibility across scales). The dataset includes five distinct task types — Video_Stream, Data_Upload, Health_Monitor, Control_Command, and AR_VR_App — covering multiple computational profiles such as latency-sensitive, bandwidth-intensive, and computation-heavy tasks. Different task categories mimic real-world MEC demands across entertainment (AR/VR, Video Streaming), healthcare (Health Monitor), industrial control (Control Commands), and IoT communication (Data Upload)(Such heterogeneity ensures that findings are not biased toward a single application domain, thus enabling broad applicability.. In practice, MEC environments interact with a wide range of devices — from basic IoT sensors to high-performance mobile clients. Devices are classified into Low-End, Mid-End, and High-End classes, each reflecting real-world differences in CPU frequencies, memory capacities, and communication behavior (varying device classes allows the evaluation framework to generalize across different hardware capabilities without favoring high-end setups).

Likewise, devices exhibit three different mobility statuses — Static, Slow-moving, and Fast-moving — affecting network quality (bandwidth and latency). User mobility is a critical variable in edge computing; mobile nodes create fluctuating wireless link qualities and dynamic handovers (Including mobility ensures that task offloading strategies tested on this dataset remain valid in dynamic and unstable environments). Overload flags are assigned based on computation load exceeding thresholds, and chaos flags are assigned when latency exceeds 40 ms, reflecting realistic network degradation scenarios. Overloads and chaotic behaviors were not assigned randomly but derived from the underlying system dynamics — linking them to tangible system stress indicators (e.g., CPU demand, network latency)(Such modeling increases realism and prevents artificial biases, ensuring robustness of evaluation results under stress). 

Task data size, computation demand, bandwidth, and latency are randomly varied within controlled realistic ranges for each sample. Real-world MEC systems encounter continuous randomness in task arrival rates, user behaviors, and resource availabilities (Such stochastic behavior enhances the dataset's ability to generalize to unpredictable environments and workload patterns). Timestamps span from January 23, 2024, to July 23, 2024, with randomized occurrences. Extending data collection over six months mimics prolonged system operation under varying seasons, usage peaks, and downtimes. Thus, temporal coverage ensures the evaluation framework captures both short-term fluctuations and long-term system behavior trends.
